# -*- coding: utf-8 -*-
"""Fake News DL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QeDItvxegOSanaydfMP6aHBh-_eVEsjL
"""

from google.colab import drive
drive.mount('/content/drive')

import  numpy as np
import pandas as pd
dat = pd.read_csv("/content/drive/MyDrive/Machine Learning /news.csv")
dat

df=pd.DataFrame(dat)
y= df['label']
y

df =df.drop(['label','Unnamed: 0','title'],axis=1)
X=df
X

from sklearn.metrics import accuracy_score,classification_report
from sklearn.model_selection import train_test_split
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer()
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)
X_train_new=cv.fit_transform(X_train['text'])
X_test_new = cv.transform(X_test['text'])

print(cv.get_feature_names())
print(np.shape(cv.get_feature_names()))
print(X_train_new.toarray())
np.shape(X_train_new.toarray())

pac = PassiveAggressiveClassifier(max_iter=50)
pac.fit(X_train_new,y_train)
y_pred = pac.predict(X_test_new)
print("Predicted value is \n",y_pred)
print("Real value is \n",y_test)

accuracy_score(y_test,y_pred)

import nltk
import re
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()
sw=stopwords.words('english')

dat = pd.read_csv("/content/drive/MyDrive/Machine Learning /news.csv")
dat

rev1 = []
for i in range(0,6335):
  new = re.sub('[^a-zA-Z]',' ',dat['title'][i])
  new = new.lower()
  new = new.split()
  new = [ps.stem(word) for word in new if not word in set(sw)]
  new =  ' '.join(new)
  rev1.append(new)
rev1

voc_size = 6000
onehot_repr=[one_hot(words,voc_size)for words in rev1]
sent_length=20
embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)
print(embedded_docs)
np.shape(embedded_docs)

from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.text import one_hot
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Bidirectional
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout

embedding_vector_features=40
model=Sequential()
model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))
model.add(Dropout(0.3))
model.add(LSTM(100)) #Adding 100 lstm neurons in the layer
model.add(Dropout(0.3))
model.add(Dense(1,activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

dat['label'] = pd.factorize(dat['label'])[0]
y = dat['label']
X_final=np.array(embedded_docs)
y_final=np.array(y)

X_train, X_test, y_train, y_test = train_test_split(X_final,y_final, test_size=0.2, random_state=42)
model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)

y_pred=model.predict(X_test)
for i in range(0,np.shape(y_pred)[0]):
  if(y_pred[i]>0.5):
    y_pred[i]=1
  else:
    y_pred[i]=0
y_pred

from sklearn.metrics import accuracy_score
accuracy_score(y_test,y_pred)

rev2 = []
for i in range(0,6335):
  new = re.sub('[^a-zA-Z]',' ',dat['text'][i])
  new = new.lower()
  new = new.split()
  new = [ps.stem(word) for word in new if not word in set(sw)]
  new =  ' '.join(new)
  rev2.append(new)
rev2

voc_size = 6000
onehot_repr=[one_hot(words,voc_size)for words in rev2]
sent_length=20
embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)
print(embedded_docs)
np.shape(embedded_docs)

dat['label'] = pd.factorize(dat['label'])[0]
y = dat['label']
X_final=np.array(embedded_docs)
y_final=np.array(y)

X_train, X_test, y_train, y_test = train_test_split(X_final,y_final, test_size=0.2, random_state=42)
model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)

y_pred=model.predict(X_test)
for i in range(0,np.shape(y_pred)[0]):
  if(y_pred[i]>0.5):
    y_pred[i]=1
  else:
    y_pred[i]=0
y_pred

from sklearn.metrics import accuracy_score
accuracy_score(y_test,y_pred)