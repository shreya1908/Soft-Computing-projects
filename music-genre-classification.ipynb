{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Dataset description\nThe dataset used here is [GTZAN](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification)\n\nThe GTZAN dataset contains 1000 audio files. \nContains a total of 10 genres, each genre contains 100 audio files\n\n1) Blues \n2) Classical\n3) Country\n4) Disco   \n5) Hip-hop \n6) Jazz   \n7) Metal \n8) Pop \n9) Reggae \n10) Rock","metadata":{}},{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"#importing all the required libraries\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport scipy\nimport os\nimport pickle\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\nfrom IPython.display import Audio\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:12.894502Z","iopub.execute_input":"2022-06-26T15:31:12.895465Z","iopub.status.idle":"2022-06-26T15:31:12.902399Z","shell.execute_reply.started":"2022-06-26T15:31:12.895423Z","shell.execute_reply":"2022-06-26T15:31:12.901294Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#reading the csv file\ndf = pd.read_csv(\"../input/gtzan-dataset-music-genre-classification/Data/features_3_sec.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:13.009542Z","iopub.execute_input":"2022-06-26T15:31:13.009898Z","iopub.status.idle":"2022-06-26T15:31:13.208950Z","shell.execute_reply.started":"2022-06-26T15:31:13.009868Z","shell.execute_reply":"2022-06-26T15:31:13.207880Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"#shape of the data\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:13.211210Z","iopub.execute_input":"2022-06-26T15:31:13.211588Z","iopub.status.idle":"2022-06-26T15:31:13.219315Z","shell.execute_reply.started":"2022-06-26T15:31:13.211551Z","shell.execute_reply":"2022-06-26T15:31:13.218407Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"#data type of the data\ndf.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:13.220856Z","iopub.execute_input":"2022-06-26T15:31:13.221507Z","iopub.status.idle":"2022-06-26T15:31:13.233986Z","shell.execute_reply.started":"2022-06-26T15:31:13.221471Z","shell.execute_reply":"2022-06-26T15:31:13.232417Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"#loading a sample audio from the dataset\naudio =\"../input/gtzan-dataset-music-genre-classification/Data/genres_original/reggae/reggae.00010.wav\"\ndata,sr=librosa.load(audio)\nprint(type(data),type(sr))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:13.280888Z","iopub.execute_input":"2022-06-26T15:31:13.281743Z","iopub.status.idle":"2022-06-26T15:31:13.293210Z","shell.execute_reply.started":"2022-06-26T15:31:13.281705Z","shell.execute_reply":"2022-06-26T15:31:13.292316Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"In order to work with audio data we use [Librosa](https://librosa.org/doc/latest/index.html), a python\npackage used for audio and music analysis. It is a powerful package widely used for\naudio visualization and for building MIR systems. We will be using the package for\nloading and visualizing the audio data.","metadata":{}},{"cell_type":"code","source":"#initializing sample rate to 45600 we obtain the signal value array\nlibrosa.load(audio,sr=45600)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:13.369540Z","iopub.execute_input":"2022-06-26T15:31:13.370324Z","iopub.status.idle":"2022-06-26T15:31:14.520837Z","shell.execute_reply.started":"2022-06-26T15:31:13.370285Z","shell.execute_reply":"2022-06-26T15:31:14.519726Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"#taking Short-time Fourier transform of the signal\ny = librosa.stft(data)  \nS_db = librosa.amplitude_to_db(np.abs(y), ref=np.max)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:14.524353Z","iopub.execute_input":"2022-06-26T15:31:14.524620Z","iopub.status.idle":"2022-06-26T15:31:14.580726Z","shell.execute_reply.started":"2022-06-26T15:31:14.524594Z","shell.execute_reply":"2022-06-26T15:31:14.579793Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"#playing audio file\nimport IPython\nIPython.display.Audio(data,rate=sr)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:14.582495Z","iopub.execute_input":"2022-06-26T15:31:14.583173Z","iopub.status.idle":"2022-06-26T15:31:14.618573Z","shell.execute_reply.started":"2022-06-26T15:31:14.583134Z","shell.execute_reply":"2022-06-26T15:31:14.617309Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"It is important to note that while working with any kind of audio data to solve any kind of problem statement, using only .wav format audio files is appropriate to analyze the data. If you are given audio files with .mp3 format you have to batch convert the data to waveforms using online software as .wav is the standard way of representing the audio files and it is the only way to work with audio data. Below is the wave form representation on the audio","metadata":{}},{"cell_type":"code","source":"#wave form of the audio\nplt.figure(figsize=(7,4))\nlibrosa.display.waveshow(data,color=\"#2B4F72\", alpha = 0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:14.621157Z","iopub.execute_input":"2022-06-26T15:31:14.621712Z","iopub.status.idle":"2022-06-26T15:31:15.039827Z","shell.execute_reply.started":"2022-06-26T15:31:14.621677Z","shell.execute_reply":"2022-06-26T15:31:15.038873Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"A spectrogram is a visual representation of the signal loudness of a signal over time at different frequencies included in a certain waveform. We can examine increase or decrease of energy over period of time. Spectrograms are also known as sonographs, voiceprints, and voicegrams.  We can also know how energy levels change over time period.","metadata":{}},{"cell_type":"code","source":"#spectrogram of the audio\nstft=librosa.stft(data)\nstft_db=librosa.amplitude_to_db(abs(stft))\nplt.figure(figsize=(7,6))\nlibrosa.display.specshow(stft_db,sr=sr,x_axis='time',y_axis='hz')\nplt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:15.041149Z","iopub.execute_input":"2022-06-26T15:31:15.041918Z","iopub.status.idle":"2022-06-26T15:31:16.021704Z","shell.execute_reply.started":"2022-06-26T15:31:15.041869Z","shell.execute_reply":"2022-06-26T15:31:16.020778Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"## Data Pre Processing","metadata":{}},{"cell_type":"code","source":"spectral_rolloff=librosa.feature.spectral_rolloff(y=data,sr=sr)[0]\nplt.figure(figsize=(7,6))\nlibrosa.display.waveshow(data,sr=sr,alpha=0.4,color=\"#2B4F72\")","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:16.023198Z","iopub.execute_input":"2022-06-26T15:31:16.023794Z","iopub.status.idle":"2022-06-26T15:31:16.475083Z","shell.execute_reply.started":"2022-06-26T15:31:16.023756Z","shell.execute_reply":"2022-06-26T15:31:16.474169Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"import librosa.display as lplt\nchroma = librosa.feature.chroma_stft(y=data,sr=sr)\nplt.figure(figsize=(7,4))\nlplt.specshow(chroma,sr=sr,x_axis=\"time\",y_axis=\"chroma\",cmap=\"BuPu\")\nplt.colorbar()\nplt.title(\"Chroma Features\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:16.476795Z","iopub.execute_input":"2022-06-26T15:31:16.477206Z","iopub.status.idle":"2022-06-26T15:31:16.940833Z","shell.execute_reply.started":"2022-06-26T15:31:16.477171Z","shell.execute_reply":"2022-06-26T15:31:16.939758Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"start=1000\nend=1200\nplt.figure(figsize=(12,4))\nplt.plot(data[start:end],color=\"#2B4F72\")","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:16.942390Z","iopub.execute_input":"2022-06-26T15:31:16.942731Z","iopub.status.idle":"2022-06-26T15:31:17.175558Z","shell.execute_reply.started":"2022-06-26T15:31:16.942695Z","shell.execute_reply":"2022-06-26T15:31:17.174689Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"#printing the number of times signal crosses the x-axis\nzero_cross_rate=librosa.zero_crossings(data[start:end],pad=False)\nprint(\"The number of zero_crossings are :\", sum(zero_cross_rate))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:17.177284Z","iopub.execute_input":"2022-06-26T15:31:17.177924Z","iopub.status.idle":"2022-06-26T15:31:17.185474Z","shell.execute_reply.started":"2022-06-26T15:31:17.177887Z","shell.execute_reply":"2022-06-26T15:31:17.184290Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis(EDA)\n","metadata":{}},{"cell_type":"code","source":"#EDA for all the music genre classes\n\n#1) BLUES \naudio1= '../input/gtzan-dataset-music-genre-classification/Data/genres_original/blues/blues.00001.wav'\ndata, sr = librosa.load(audio1)\nplt.figure(figsize=(7, 3))\nlibrosa.display.waveshow(data, sr=sr,alpha=0.4,)\nplt.title('Waveplot - BLUES')\n\n#creating log mel spectrogram\nplt.figure(figsize=(7, 4))\nspectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128,fmax=8000) \nspectrogram = librosa.power_to_db(spectrogram)\nlibrosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\nplt.title('Mel Spectrogram - BLUES')\nplt.colorbar(format='%+2.0f dB');\n# playing audio\nipd.Audio(audio1) ","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:17.189789Z","iopub.execute_input":"2022-06-26T15:31:17.191034Z","iopub.status.idle":"2022-06-26T15:31:18.249198Z","shell.execute_reply.started":"2022-06-26T15:31:17.190997Z","shell.execute_reply":"2022-06-26T15:31:18.248138Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"#2) CLASSICAL -\naudio1= '../input/gtzan-dataset-music-genre-classification/Data/genres_original/classical/classical.00001.wav'\ndata, sr = librosa.load(audio1)\nplt.figure(figsize=(7, 3))\nlibrosa.display.waveshow(data, sr=sr,alpha=0.4)\nplt.title('Waveplot - CLASSICAL') \n\n#creating log mel spectrogram\nplt.figure(figsize=(7, 4))\nspectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128,fmax=8000) \nspectrogram = librosa.power_to_db(spectrogram)\nlibrosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\nplt.title('Mel Spectrogram -CLASSICAL')\nplt.colorbar(format='%+2.0f dB');\n\n#playing audio\nipd.Audio(audio1) ","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:18.251134Z","iopub.execute_input":"2022-06-26T15:31:18.251960Z","iopub.status.idle":"2022-06-26T15:31:19.220621Z","shell.execute_reply.started":"2022-06-26T15:31:18.251918Z","shell.execute_reply":"2022-06-26T15:31:19.219705Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"#3) COUNTRY\naudio1= '../input/gtzan-dataset-music-genre-classification/Data/genres_original/country/country.00001.wav'\ndata, sr = librosa.load(audio1)\nplt.figure(figsize=(7, 3))\nlibrosa.display.waveshow(data, sr=sr,alpha=0.4)\nplt.title('Waveplot - COUNTRY')\n\n#creating log mel spectrogram\nplt.figure(figsize=(7, 4))\nspectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128,fmax=8000) \nspectrogram = librosa.power_to_db(spectrogram)\nlibrosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\nplt.title('Mel Spectrogram - COUNTRY')\nplt.colorbar(format='%+2.0f dB');\n\n#playing audio\nipd.Audio(audio1)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:19.222137Z","iopub.execute_input":"2022-06-26T15:31:19.223202Z","iopub.status.idle":"2022-06-26T15:31:20.399775Z","shell.execute_reply.started":"2022-06-26T15:31:19.223148Z","shell.execute_reply":"2022-06-26T15:31:20.398861Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"#4) DISCO\naudio1= '../input/gtzan-dataset-music-genre-classification/Data/genres_original/disco/disco.00001.wav'\ndata, sr = librosa.load(audio1)\nplt.figure(figsize=(7, 3))\nlibrosa.display.waveshow(data, sr=sr,alpha=0.4)\nplt.title('Waveplot - DISCO')\n\n#creating log mel spectrogram\nplt.figure(figsize=(7, 4))\nspectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128,fmax=8000) \nspectrogram = librosa.power_to_db(spectrogram)\nlibrosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\nplt.title('Mel Spectrogram - DISCO')\nplt.colorbar(format='%+2.0f dB');\n# playing audio\nipd.Audio(audio1) ","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:20.401034Z","iopub.execute_input":"2022-06-26T15:31:20.401751Z","iopub.status.idle":"2022-06-26T15:31:21.333205Z","shell.execute_reply.started":"2022-06-26T15:31:20.401710Z","shell.execute_reply":"2022-06-26T15:31:21.332283Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"#5) HIPHOP\naudio1= '../input/gtzan-dataset-music-genre-classification/Data/genres_original/hiphop/hiphop.00001.wav'\ndata, sr = librosa.load(audio1)\nplt.figure(figsize=(7, 3))\nlibrosa.display.waveshow(data, sr=sr, alpha = 0.4)\nplt.title('Waveplot - HIPHOP')\n\n#creating log mel spectrogram \nplt.figure(figsize=(7, 4))\nspectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128,fmax=8000,) \nspectrogram = librosa.power_to_db(spectrogram)\nlibrosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\nplt.title('Mel Spectrogram - HIPHOP')\nplt.colorbar(format='%+2.0f dB');\n\n#playing audio\nipd.Audio(audio1)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:21.334785Z","iopub.execute_input":"2022-06-26T15:31:21.335356Z","iopub.status.idle":"2022-06-26T15:31:22.292626Z","shell.execute_reply.started":"2022-06-26T15:31:21.335320Z","shell.execute_reply":"2022-06-26T15:31:22.291719Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"#6) JAZZ\naudio1= '../input/gtzan-dataset-music-genre-classification/Data/genres_original/jazz/jazz.00001.wav'\ndata, sr = librosa.load(audio1)\nplt.figure(figsize=(7, 3))\nlibrosa.display.waveshow(data, sr=sr,alpha=0.4)\nplt.title('Waveplot - JAZZ')\n\n#creating log mel spectrogram\nplt.figure(figsize=(7, 4))\nspectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128,fmax=8000) \nspectrogram = librosa.power_to_db(spectrogram)\nlibrosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\nplt.title('Mel Spectrogram - JAZZ')\nplt.colorbar(format='%+2.0f dB');\n\n#playing audio\nipd.Audio(audio1)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:22.294005Z","iopub.execute_input":"2022-06-26T15:31:22.294619Z","iopub.status.idle":"2022-06-26T15:31:23.161898Z","shell.execute_reply.started":"2022-06-26T15:31:22.294581Z","shell.execute_reply":"2022-06-26T15:31:23.160851Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"#7) METAL\naudio1= '../input/gtzan-dataset-music-genre-classification/Data/genres_original/metal/metal.00001.wav'\ndata, sr = librosa.load(audio1)\nplt.figure(figsize=(7, 3))\nlibrosa.display.waveshow(data, sr=sr,alpha=0.4)\nplt.title('Waveplot - METAL')\n\n#creating log mel spectrogram\nplt.figure(figsize=(7, 4))\nspectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128,fmax=8000) \nspectrogram = librosa.power_to_db(spectrogram)\nlibrosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\nplt.title('Mel Spectrogram - METAL')\nplt.colorbar(format='%+2.0f dB');\n\n#playing audio\nipd.Audio(audio1)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:23.163325Z","iopub.execute_input":"2022-06-26T15:31:23.164293Z","iopub.status.idle":"2022-06-26T15:31:24.095663Z","shell.execute_reply.started":"2022-06-26T15:31:23.164255Z","shell.execute_reply":"2022-06-26T15:31:24.094737Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"#8) POP\naudio1= '../input/gtzan-dataset-music-genre-classification/Data/genres_original/pop/pop.00001.wav'\ndata, sr = librosa.load(audio1)\nplt.figure(figsize=(8, 3))\nlibrosa.display.waveshow(data, sr=sr,alpha=0.4)\nplt.title('Waveplot - POP') \n\n#creating log mel spectrogram\nplt.figure(figsize=(7, 4))\nspectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128,fmax=8000) \nspectrogram = librosa.power_to_db(spectrogram)\nlibrosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\nplt.title('Mel Spectrogram - POP')\nplt.colorbar(format='%+2.0f dB');\n\n#playing audio\nipd.Audio(audio1)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:24.097265Z","iopub.execute_input":"2022-06-26T15:31:24.097892Z","iopub.status.idle":"2022-06-26T15:31:25.040587Z","shell.execute_reply.started":"2022-06-26T15:31:24.097853Z","shell.execute_reply":"2022-06-26T15:31:25.039739Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"#9) REGGAE\naudio1= '../input/gtzan-dataset-music-genre-classification/Data/genres_original/reggae/reggae.00001.wav'\ndata, sr = librosa.load(audio1)\nplt.figure(figsize=(7, 3))\nlibrosa.display.waveshow(data, sr=sr,alpha=0.4)\nplt.title('Waveplot - REGGAE')\n\n#creating log mel spectrogram\nplt.figure(figsize=(7, 4))\nspectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128,fmax=8000) \nspectrogram = librosa.power_to_db(spectrogram)\nlibrosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\nplt.title('Mel Spectrogram - REGGAE')\nplt.colorbar(format='%+2.0f dB');\n\n#playing audio\nipd.Audio(audio1)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:25.041996Z","iopub.execute_input":"2022-06-26T15:31:25.042986Z","iopub.status.idle":"2022-06-26T15:31:25.942555Z","shell.execute_reply.started":"2022-06-26T15:31:25.042946Z","shell.execute_reply":"2022-06-26T15:31:25.941723Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"#10) ROCK\naudio1= '../input/gtzan-dataset-music-genre-classification/Data/genres_original/rock/rock.00001.wav'\ndata, sr = librosa.load(audio1)\nplt.figure(figsize=(7, 3))\nlibrosa.display.waveshow(data, sr=sr,alpha=0.4)\nplt.title('Waveplot - ROCK')\n\n#creating log mel spectrogram\nplt.figure(figsize=(7, 4))\nspectrogram = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128,fmax=8000) \nspectrogram = librosa.power_to_db(spectrogram)\nlibrosa.display.specshow(spectrogram, y_axis='mel', fmax=8000, x_axis='time');\nplt.title('Mel Spectrogram - ROCK')\nplt.colorbar(format='%+2.0f dB');\n\n#playing audio\nipd.Audio(audio1)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:25.943945Z","iopub.execute_input":"2022-06-26T15:31:25.944868Z","iopub.status.idle":"2022-06-26T15:31:26.875566Z","shell.execute_reply.started":"2022-06-26T15:31:25.944828Z","shell.execute_reply":"2022-06-26T15:31:26.874722Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"#finding misssing values and all columns with any NA values\nprint(\"Columns containing missing values\",list(df.columns[df.isnull().any()]))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:26.877191Z","iopub.execute_input":"2022-06-26T15:31:26.877881Z","iopub.status.idle":"2022-06-26T15:31:26.890195Z","shell.execute_reply.started":"2022-06-26T15:31:26.877820Z","shell.execute_reply":"2022-06-26T15:31:26.888785Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"#Label Encoding\n\n# Blues - 0\n# Classical - 1\n# Country - 2\n# Disco - 3\n# Hip-hop - 4 \n# Jazz - 5  \n# Metal - 6 \n# Pop - 7\n# Reggae - 8\n# Rock - 9\n\nclass_encod=df.iloc[:,-1]\nconverter=LabelEncoder()\ny=converter.fit_transform(class_encod)\ny","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:26.891605Z","iopub.execute_input":"2022-06-26T15:31:26.892282Z","iopub.status.idle":"2022-06-26T15:31:26.903240Z","shell.execute_reply.started":"2022-06-26T15:31:26.892243Z","shell.execute_reply":"2022-06-26T15:31:26.901864Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"#features\nprint(df.iloc[:,:-1])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:26.904360Z","iopub.execute_input":"2022-06-26T15:31:26.904634Z","iopub.status.idle":"2022-06-26T15:31:26.926344Z","shell.execute_reply.started":"2022-06-26T15:31:26.904601Z","shell.execute_reply":"2022-06-26T15:31:26.925474Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"#drop the column filename as it is no longer required for training\ndf=df.drop(labels=\"filename\",axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:26.928149Z","iopub.execute_input":"2022-06-26T15:31:26.928520Z","iopub.status.idle":"2022-06-26T15:31:26.936387Z","shell.execute_reply.started":"2022-06-26T15:31:26.928484Z","shell.execute_reply":"2022-06-26T15:31:26.935487Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"#scaling\nfrom sklearn.preprocessing import StandardScaler\nfit=StandardScaler()\nX=fit.fit_transform(np.array(df.iloc[:,:-1],dtype=float))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:26.939135Z","iopub.execute_input":"2022-06-26T15:31:26.940033Z","iopub.status.idle":"2022-06-26T15:31:26.955276Z","shell.execute_reply.started":"2022-06-26T15:31:26.939999Z","shell.execute_reply":"2022-06-26T15:31:26.954440Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"#splitting 70% data into training set and the remaining 30% to test set\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:26.956602Z","iopub.execute_input":"2022-06-26T15:31:26.956987Z","iopub.status.idle":"2022-06-26T15:31:26.964932Z","shell.execute_reply.started":"2022-06-26T15:31:26.956949Z","shell.execute_reply":"2022-06-26T15:31:26.963974Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"#test data size\nlen(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:26.967039Z","iopub.execute_input":"2022-06-26T15:31:26.967641Z","iopub.status.idle":"2022-06-26T15:31:26.976263Z","shell.execute_reply.started":"2022-06-26T15:31:26.967532Z","shell.execute_reply":"2022-06-26T15:31:26.975141Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"#size of training data\nlen(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:26.978310Z","iopub.execute_input":"2022-06-26T15:31:26.978784Z","iopub.status.idle":"2022-06-26T15:31:26.987531Z","shell.execute_reply.started":"2022-06-26T15:31:26.978749Z","shell.execute_reply":"2022-06-26T15:31:26.986354Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"## K-Nearest Neighbors (KNN)","metadata":{}},{"cell_type":"code","source":"#applying K nearest Neighbour algorithm to predict the results\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nclf1=KNeighborsClassifier(n_neighbors=3)\nclf1.fit(X_train,y_train)\ny_pred=clf1.predict(X_test)\nprint(\"Training set score: {:.3f}\".format(clf1.score(X_train, y_train)))\nprint(\"Test set score: {:.3f}\".format(clf1.score(X_test, y_test)))\ncf_matrix = confusion_matrix(y_test, y_pred)\nsns.set(rc = {'figure.figsize':(8,3)})\nsns.heatmap(cf_matrix, annot=True)\nprint(classification_report(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:26.994016Z","iopub.execute_input":"2022-06-26T15:31:26.994257Z","iopub.status.idle":"2022-06-26T15:31:29.660583Z","shell.execute_reply.started":"2022-06-26T15:31:26.994235Z","shell.execute_reply":"2022-06-26T15:31:29.659683Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"## Support Vector Machine (SVM)","metadata":{}},{"cell_type":"code","source":"#applying Support Vector Machines to predict the results\nfrom sklearn.svm import SVC\nsvclassifier = SVC(kernel='rbf', degree=8)\nsvclassifier.fit(X_train, y_train)\nprint(\"Training set score: {:.3f}\".format(svclassifier.score(X_train, y_train)))\nprint(\"Test set score: {:.3f}\".format(svclassifier.score(X_test, y_test)))\ny_pred = svclassifier.predict(X_test)\ncf_matrix3 = confusion_matrix(y_test, y_pred)\nsns.set(rc = {'figure.figsize':(9,4)})\nsns.heatmap(cf_matrix3, annot=True)\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:29.662153Z","iopub.execute_input":"2022-06-26T15:31:29.662788Z","iopub.status.idle":"2022-06-26T15:31:39.249704Z","shell.execute_reply.started":"2022-06-26T15:31:29.662749Z","shell.execute_reply":"2022-06-26T15:31:39.248766Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"## Convolutional Neural Networks (CNN)","metadata":{}},{"cell_type":"code","source":"#training the model\ndef train_model(model,epochs,optimizer):\n    batch_size=256\n    model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics='accuracy')\n    return model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=epochs,batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:39.251193Z","iopub.execute_input":"2022-06-26T15:31:39.251759Z","iopub.status.idle":"2022-06-26T15:31:39.258481Z","shell.execute_reply.started":"2022-06-26T15:31:39.251721Z","shell.execute_reply":"2022-06-26T15:31:39.257472Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"def Validation_plot(history):\n    print(\"Validation Accuracy\",max(history.history[\"val_accuracy\"]))\n    pd.DataFrame(history.history).plot(figsize=(12,6))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:39.260125Z","iopub.execute_input":"2022-06-26T15:31:39.260521Z","iopub.status.idle":"2022-06-26T15:31:39.268490Z","shell.execute_reply.started":"2022-06-26T15:31:39.260483Z","shell.execute_reply":"2022-06-26T15:31:39.267475Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"model=tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=(X.shape[1],)),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Dense(512,activation='relu'),\n    keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Dense(256,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Dense(128,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Dense(64,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Dense(32,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Dense(10,activation='softmax'),\n])\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.000146)\nmodel.compile(optimizer=optimizer,\n             loss=\"sparse_categorical_crossentropy\",\n              metrics=[\"accuracy\"])\nmodel.summary()\nmodel_history=train_model(model=model,epochs=500,optimizer='adam')\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:31:39.271186Z","iopub.execute_input":"2022-06-26T15:31:39.271448Z","iopub.status.idle":"2022-06-26T15:32:35.889437Z","shell.execute_reply.started":"2022-06-26T15:31:39.271425Z","shell.execute_reply":"2022-06-26T15:32:35.888466Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"test_loss,test_acc=model.evaluate(X_test,y_test,batch_size=256)\nprint(\"The test loss is \",test_loss)\nprint(\"The best accuracy is: \",test_acc*100)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:32:35.891987Z","iopub.execute_input":"2022-06-26T15:32:35.893029Z","iopub.status.idle":"2022-06-26T15:32:36.001223Z","shell.execute_reply.started":"2022-06-26T15:32:35.892987Z","shell.execute_reply":"2022-06-26T15:32:36.000211Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"#the plot dipicts how training and testing data performed\nValidation_plot(model_history)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:32:36.004028Z","iopub.execute_input":"2022-06-26T15:32:36.004440Z","iopub.status.idle":"2022-06-26T15:32:36.292140Z","shell.execute_reply.started":"2022-06-26T15:32:36.004412Z","shell.execute_reply":"2022-06-26T15:32:36.291067Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"#sample testing\nsample = X_test\nsample = sample[np.newaxis, ...]\nprediction = model.predict(X_test)\npredicted_index = np.argmax(prediction, axis = 1)\nprint(\"Expected Index: {}, Predicted Index: {}\".format(y_test, predicted_index))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:32:36.294392Z","iopub.execute_input":"2022-06-26T15:32:36.294873Z","iopub.status.idle":"2022-06-26T15:32:36.530941Z","shell.execute_reply.started":"2022-06-26T15:32:36.294831Z","shell.execute_reply":"2022-06-26T15:32:36.529940Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"#plotting the confusion matrix for analizing the true positives and negatives\nimport seaborn as sn\nimport matplotlib.pyplot as plt\npred_x = model.predict(X_test)\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test,predicted_index )\ncm\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:32:36.532626Z","iopub.execute_input":"2022-06-26T15:32:36.533051Z","iopub.status.idle":"2022-06-26T15:32:36.666889Z","shell.execute_reply.started":"2022-06-26T15:32:36.533015Z","shell.execute_reply":"2022-06-26T15:32:36.665850Z"},"trusted":true},"execution_count":82,"outputs":[]}]}